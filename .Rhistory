##### Proportion of other packages that Author worked on  ####
message("Creating Proportion of other packages that Author worked on feature matrix")
authors_of_packages = All_data$pac_network$nodes$author
names(authors_of_packages) = All_data$pac_network$nodes$package
authors_of_packages = authors_of_packages[input_CRAN_data$all_CRAN_pks]
packages_of_authors = All_data$aut_network$nodes$package
names(packages_of_authors) = All_data$aut_network$nodes$author
fun1 = function(x){
# when given a vector of Authors, returns a vector of the proportion of the Task Views of the packages qorked on by the authors
z = unlist(taskviews_of_pckgs[unique(unlist(packages_of_authors[x]))])
if(is.null(z)){
author_tsk_view_prop = c(rep(0,length(RWsearch::tvdb_vec(tvdb))),1)
names(author_tsk_view_prop) = c(RWsearch::tvdb_vec(tvdb), "none")
}else{
author_tsk_view_prop = prop.table(table(z))
mat_fill = matrix(0, nrow = 1, ncol = length(RWsearch::tvdb_vec(tvdb)) + 1)
colnames(mat_fill) = c(RWsearch::tvdb_vec(tvdb), "none")
mat_fill[1,names(author_tsk_view_prop)] = as.vector(author_tsk_view_prop)
author_tsk_view_prop = mat_fill
}
return(author_tsk_view_prop)
}
feature_matrix_author_task_views = pbapply::pblapply(authors_of_packages, fun1)
feature_matrix_author_task_views = do.call(rbind, feature_matrix_author_task_views)
row.names(feature_matrix_author_task_views) = names(authors_of_packages)
colnames(feature_matrix_author_task_views) = paste0(colnames(feature_matrix_author_task_views), ".Author_props")
# merging feature matrices
feature_matrix_all_neighbour_pkgs_df = as.data.frame(feature_matrix_all_neighbour_pkgs)
feature_matrix_author_task_views_df = as.data.frame(feature_matrix_author_task_views)
feature_matrix_titles_descriptions_packages_cosine_df = as.data.frame(get_NLP_output$feature_matrix_titles_descriptions_packages_cosine)
feature_matrix_titles_descriptions_packages_cosine_df = t(feature_matrix_titles_descriptions_packages_cosine_df)
# Making sure all feature matrices and response matrix have correct rownames in correct order
# Response matrix
response_matrix
# Package Dependencies
feature_matrix_all_neighbour_pkgs
# Text data
feature_matrix_titles_descriptions_packages_cosine_df
feature_matrix_titles_descriptions_packages_cosine_df = feature_matrix_titles_descriptions_packages_cosine_df[input_CRAN_data$all_CRAN_pks,]
feature_matrix_titles_descriptions_packages_cosine_df
# Author collaborators
feature_matrix_author_task_views
# Create a final vector of package names that have rows for all the feature matrices and response matrix
# So what I have done is used rows that have data for all of the feature matrices and the response matrix
final_package_names =
Reduce(intersect,list(row.names(response_matrix),
row.names(feature_matrix_all_neighbour_pkgs),
row.names(feature_matrix_titles_descriptions_packages_cosine_df),
row.names(feature_matrix_author_task_views)))
final_package_names = unique(final_package_names)
response_matrix                                       = response_matrix[final_package_names,]
feature_matrix_all_neighbour_pkgs                     = feature_matrix_all_neighbour_pkgs[final_package_names,]
feature_matrix_titles_descriptions_packages_cosine_df = feature_matrix_titles_descriptions_packages_cosine_df[final_package_names,]
feature_matrix_author_task_views                      = feature_matrix_author_task_views[final_package_names,]
# Double checking duplicates
response_matrix                                       = response_matrix[!duplicated(row.names(response_matrix)),]
feature_matrix_all_neighbour_pkgs                     = feature_matrix_all_neighbour_pkgs[!duplicated(row.names(feature_matrix_all_neighbour_pkgs)),]
feature_matrix_titles_descriptions_packages_cosine_df = feature_matrix_titles_descriptions_packages_cosine_df[!duplicated(row.names(feature_matrix_titles_descriptions_packages_cosine_df)),]
feature_matrix_author_task_views                      = feature_matrix_author_task_views[!duplicated(row.names(feature_matrix_author_task_views)),]
features = merge(feature_matrix_titles_descriptions_packages_cosine_df, feature_matrix_all_neighbour_pkgs_df, by="row.names", all.x = TRUE, )
rownames(features) = features[,"Row.names"]
features = features[,colnames(features) != "Row.names"]
colnames(features) = gsub(colnames(features), pattern = "\\.x", replacement = ".text")
colnames(features) = gsub(colnames(features), pattern = "\\.y", replacement = ".neigh_packs")
features = merge(features, feature_matrix_author_task_views_df, by="row.names", all.x = TRUE)
# features = as.numeric(as.matrix(features))
nrow(features)
rownames(features) = features[,"Row.names"]
features = features[,colnames(features) != "Row.names"]
debugSource("~/Documents/Projects/CTVsuggest/R/get_create_features.R")
get_create_features(TEST = T)
get_create_features(TEST = T)
input_CRAN_data$CRAN_cranly_data
View(get_create_features)
TEST = T
limiting_n_observations = 10
get_NLP_output = CTVsuggest:::get_NLP(TEST = TEST, limiting_n_observations = limiting_n_observations)
input_CRAN_data = get_NLP_output$input_CRAN_data
tvdb = input_CRAN_data$tvdb
# Identifying packages with no authors
index_of_no_authors = which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0)
# replacing with maintainers
if(length(which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0)) > 0){
for(i in 1:length(which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0))){
#i = 1
input_CRAN_data$CRAN_cranly_data$author[[index_of_no_authors[i]]] = input_CRAN_data$CRAN_cranly_data$maintainer[index_of_no_authors[i]]
}
}
##### Building author and package networks ####
# All_data = board %>% pin_read("All_data")
aut_network <- cranly::build_network(input_CRAN_data$CRAN_cranly_data, perspective = 'author')
input_CRAN_data$CRAN_cranly_data
pac_network <- cranly::build_network(input_CRAN_data$CRAN_cranly_data, perspective = 'package')
input_CRAN_data$CRAN_cranly_data
cranly::build_network(input_CRAN_data$CRAN_cranly_data, perspective = 'package')
input_CRAN_data$CRAN_cranly_data
##### Building author and package networks ####
# All_data = board %>% pin_read("All_data")
aut_network <- cranly::build_network(input_CRAN_data$CRAN_cranly_data, perspective = 'author')
aut_network
pac_network <- cranly::build_network(input_CRAN_data$CRAN_cranly_data, perspective = 'package')
TEST = T
limiting_n_observations = 1000
get_NLP_output = CTVsuggest:::get_NLP(TEST = TEST, limiting_n_observations = limiting_n_observations)
input_CRAN_data = get_NLP_output$input_CRAN_data
tvdb = input_CRAN_data$tvdb
# Identifying packages with no authors
index_of_no_authors = which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0)
# replacing with maintainers
if(length(which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0)) > 0){
for(i in 1:length(which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0))){
#i = 1
input_CRAN_data$CRAN_cranly_data$author[[index_of_no_authors[i]]] = input_CRAN_data$CRAN_cranly_data$maintainer[index_of_no_authors[i]]
}
}
##### Building author and package networks ####
# All_data = board %>% pin_read("All_data")
aut_network <- cranly::build_network(input_CRAN_data$CRAN_cranly_data, perspective = 'author')
pac_network <- cranly::build_network(input_CRAN_data$CRAN_cranly_data, perspective = 'package')
All_data = list("aut_network" = aut_network, "pac_network" = pac_network)
# All_data_igraph = as.igraph(All_data$pac_network)
pac_network_igraph = igraph::as.igraph(All_data$pac_network)
# Just looking at Packages with assigned task view
# Packages that are assigned to a Task View and are not hosted on CRAN
not_in_CRAN = Reduce(c,RWsearch::tvdb_pkgs(RWsearch::tvdb_vec(input_CRAN_data$tvdb)))[!(Reduce(c,RWsearch::tvdb_pkgs(RWsearch::tvdb_vec(input_CRAN_data$tvdb))) %in% input_CRAN_data$CRAN_data$Package)]
RWsearch::tvdb_vec
input_CRAN_data$tvdb
RWsearch::tvdb_pkgs
debugSource("~/Documents/Projects/CTVsuggest/R/get_create_features.R")
debugSource("~/Documents/Projects/CTVsuggest/R/get_create_features.R")
get_create_features(TEST = T)
debugSource("~/Documents/Projects/CTVsuggest/R/get_create_features.R")
debugSource("~/Documents/Projects/CTVsuggest/R/get_create_features.R")
debugSource("~/Documents/Projects/CTVsuggest/R/get_create_features.R")
get_create_features(TEST = T)
debugSource("~/Documents/Projects/CTVsuggest/R/get_create_features.R")
get_create_features(TEST = T, limiting_n_observations = 400)
debugSource("~/Documents/Projects/CTVsuggest/R/get_create_features.R")
View(get_create_features)
View(get_create_features)
get_create_features = function(TEST = FALSE, limiting_n_observations = 100){
get_NLP_output = CTVsuggest:::get_NLP(TEST = TEST, limiting_n_observations = limiting_n_observations)
input_CRAN_data = get_NLP_output$input_CRAN_data
tvdb = input_CRAN_data$tvdb
#### Objects needed to run generated by previous script ####
# tvdb
# CRAN_data
# CRAN_cranly_data
# all_CRAN_pks
# feature_matrix_titles_descriptions_packages_cosine
##### Objects Outputted ####
# response_matrix
# features
# All_data
# pac_network_igraph
#########
#### Replacing missing authors with maintainers ####
# For some packages on CRAN the authors have not been listed in the standard way.
# Which causes these packages to have zero authors listed.
# The work around I have used is by setting the maintainer as the author
# Identifying packages with no authors
index_of_no_authors = which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0)
# replacing with maintainers
if(length(which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0)) > 0){
for(i in 1:length(which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0))){
#i = 1
input_CRAN_data$CRAN_cranly_data$author[[index_of_no_authors[i]]] = input_CRAN_data$CRAN_cranly_data$maintainer[index_of_no_authors[i]]
}
}
#######
##### Building author and package networks ####
# All_data = board %>% pin_read("All_data")
aut_network <- cranly::build_network(input_CRAN_data$CRAN_cranly_data, perspective = 'author')
pac_network <- cranly::build_network(input_CRAN_data$CRAN_cranly_data, perspective = 'package')
All_data = list("aut_network" = aut_network, "pac_network" = pac_network)
# board %>% pin_write(All_data, "All_data", type = "rds")
# All_data_igraph = as.igraph(All_data$pac_network)
pac_network_igraph = igraph::as.igraph(All_data$pac_network)
# Just looking at Packages with assigned task view
# Packages that are assigned to a Task View and are not hosted on CRAN
not_in_CRAN = Reduce(c,RWsearch::tvdb_pkgs(RWsearch::tvdb_vec(tvdb = input_CRAN_data$tvdb)))[!(Reduce(c,RWsearch::tvdb_pkgs(char = RWsearch::tvdb_vec(input_CRAN_data$tvdb))) %in% input_CRAN_data$CRAN_data$Package)]
packages_assigned_Task_View = Reduce(c,RWsearch::tvdb_pkgs(RWsearch::tvdb_vec(input_CRAN_data$tvdb)))
# Removing the packages that are not hosted on CRAN
packages_assigned_Task_View = packages_assigned_Task_View[!(packages_assigned_Task_View %in% not_in_CRAN)]
# Removing duplicates
packages_assigned_Task_View = unique(packages_assigned_Task_View)
#######
# Just looking at Hard Depenedencies
# dep_imp_edges = which(!is.element(E(All_taskviews_igraph)$type, c("depends","imports", "linking_to")))
# All_taskviews_rem_edges_igraph = delete.edges(All_taskviews_igraph, dep_imp_edges)
##########################################################################################
#### Creating list of packages with the task views assigned to each one ####
# taskviews_of_pckgs     = board %>% pin_read("taskviews_of_pckgs")
# This code is a modified version of the generating_taskviews script
taskviews_of_pckgs = vector(mode = "list", length = length(packages_assigned_Task_View))
for(j in 1:length(packages_assigned_Task_View)){
for(i in 1:length(tvdb)){
print(paste(j,i))
if(packages_assigned_Task_View[j] %in% RWsearch::tvdb_pkgs(RWsearch::tvdb_vec(tvdb)[i])) {
taskviews_of_pckgs[[j]] = append(taskviews_of_pckgs[[j]], RWsearch::tvdb_vec(tvdb)[i])
}
}
}
names(taskviews_of_pckgs) = packages_assigned_Task_View
#taskviews_of_pckgs$trackeR
# board %>% pin_write(taskviews_of_pckgs, "taskviews_of_pckgs", type = "rds")
##########################################################################################
########## Creating the response matrix #######
response_matrix = matrix(0, nrow = length(input_CRAN_data$all_CRAN_pks), ncol = length(RWsearch::tvdb_vec(tvdb)) + 1)
colnames(response_matrix) = c(RWsearch::tvdb_vec(tvdb), "none")
# Creating matrix that denotes which Task View(s) each package belongs to
for(i in 1:length(input_CRAN_data$all_CRAN_pks)){
#i = 6214
#i = 13672
if(is.null(taskviews_of_pckgs[[input_CRAN_data$all_CRAN_pks[i]]])){
response_matrix[i,"none"] = 1
} else {
response_matrix[i,taskviews_of_pckgs[[input_CRAN_data$all_CRAN_pks[i]]]] = 1
}
}
rownames(response_matrix) = input_CRAN_data$all_CRAN_pks
#response_matrix["trackeR",]
##########################################################################################
########## Creating features/predictors ######
##### Creating  Proportion of neighboring packages feature matrix ####
message("Creating  Proportion of neighboring packages feature matrix")
# creating graph object removing soft dependencies
# Giving a Task View attribute to the pac_network
pac_network_igraph = igraph::set_vertex_attr(pac_network_igraph, name = "taskview",
index = packages_assigned_Task_View,
taskviews_of_pckgs[packages_assigned_Task_View])
# check:
# V(pac_network_igraph)$taskview[V(pac_network_igraph)$name == "ggplot2"]
# V(pac_network_igraph)$taskview[V(pac_network_igraph)$name == "trackeR"]
# Deleting the soft dependencies between packages
soft_dependencies_edges = which(!is.element(igraph::E(pac_network_igraph)$type, c("depends","imports", "linking_to")))
taskviews_pac_network_rem_edges_igraph = igraph::delete.edges(pac_network_igraph, soft_dependencies_edges)
# feature_matrix_all_neighbour_pkgs     = board %>% pin_read("feature_matrix_all_neighbour_pkgs")
# Creating matrix where for each package it gives the proportion of immediate hard dependencies.
# In the `neighbours` function `mode` is set to `c("all")` meaning that we are looking at on both
# dependencies of a package and its reverse dependencies.
feature_matrix_all_neighbour_pkgs = matrix(0, nrow = length(input_CRAN_data$all_CRAN_pks), ncol = length(RWsearch::tvdb_vec(tvdb)) + 1)
colnames(feature_matrix_all_neighbour_pkgs) = c(RWsearch::tvdb_vec(tvdb), "none")
for(i in 1:length(input_CRAN_data$all_CRAN_pks)){
print(i)
neigh = igraph::neighbors(taskviews_pac_network_rem_edges_igraph, input_CRAN_data$all_CRAN_pks[i], mode = c("all"))$taskview
n_none = sum(unlist(lapply(neigh, function(x){is.null(x)})))
props = (prop.table(table(c(unlist(neigh), rep("none", n_none)))))
feature_matrix_all_neighbour_pkgs[i,names(props)] = as.vector(props)
}
rownames(feature_matrix_all_neighbour_pkgs) = input_CRAN_data$all_CRAN_pks
##### Load Features using text data of packages #####
# This has been created in the NLP R script. Reliant on the number of package available on GitHub page.
##### Proportion of other packages that Author worked on  ####
message("Creating Proportion of other packages that Author worked on feature matrix")
# feature_matrix_author_task_views = board %>% pin_read("feature_matrix_author_task_views")
# calculated by taking the authors of the package, getting the packages that they worked on.
# Then looking at the proportion of the assignment to Task Views of these packages
authors_of_packages = All_data$pac_network$nodes$author
names(authors_of_packages) = All_data$pac_network$nodes$package
authors_of_packages = authors_of_packages[input_CRAN_data$all_CRAN_pks]
packages_of_authors = All_data$aut_network$nodes$package
names(packages_of_authors) = All_data$aut_network$nodes$author
fun1 = function(x){
# when given a vector of Authors, returns a vector of the proportion of the Task Views of the packages qorked on by the authors
z = unlist(taskviews_of_pckgs[unique(unlist(packages_of_authors[x]))])
if(is.null(z)){
author_tsk_view_prop = c(rep(0,length(RWsearch::tvdb_vec(tvdb))),1)
names(author_tsk_view_prop) = c(RWsearch::tvdb_vec(tvdb), "none")
}else{
author_tsk_view_prop = prop.table(table(z))
mat_fill = matrix(0, nrow = 1, ncol = length(RWsearch::tvdb_vec(tvdb)) + 1)
colnames(mat_fill) = c(RWsearch::tvdb_vec(tvdb), "none")
mat_fill[1,names(author_tsk_view_prop)] = as.vector(author_tsk_view_prop)
author_tsk_view_prop = mat_fill
}
return(author_tsk_view_prop)
}
feature_matrix_author_task_views = pbapply::pblapply(authors_of_packages, fun1)
feature_matrix_author_task_views = do.call(rbind, feature_matrix_author_task_views)
row.names(feature_matrix_author_task_views) = names(authors_of_packages)
colnames(feature_matrix_author_task_views) = paste0(colnames(feature_matrix_author_task_views), ".Author_props")
##########################################################################################
########## Creating training and testing data sets ##########################################################################################
# I am going to split the labeled data with 80:20 ratio
# The labeled data consists of:
#             > Packages with assigned Task Views
#             > Packages with no Task View that meet assigned download Threshold
# merging feature matrices
feature_matrix_all_neighbour_pkgs_df = as.data.frame(feature_matrix_all_neighbour_pkgs)
feature_matrix_author_task_views_df = as.data.frame(feature_matrix_author_task_views)
feature_matrix_titles_descriptions_packages_cosine_df = as.data.frame(get_NLP_output$feature_matrix_titles_descriptions_packages_cosine)
feature_matrix_titles_descriptions_packages_cosine_df = t(feature_matrix_titles_descriptions_packages_cosine_df)
# Making sure all feature matrices and response matrix have correct rownames in correct order
# Response matrix
response_matrix
# Package Dependencies
feature_matrix_all_neighbour_pkgs
# Text data
feature_matrix_titles_descriptions_packages_cosine_df
feature_matrix_titles_descriptions_packages_cosine_df = feature_matrix_titles_descriptions_packages_cosine_df[input_CRAN_data$all_CRAN_pks,]
feature_matrix_titles_descriptions_packages_cosine_df
# Author collaborators
feature_matrix_author_task_views
# Create a final vector of package names that have rows for all the feature matrices and response matrix
# So what I have done is used rows that have data for all of the feature matrices and the response matrix
final_package_names =
Reduce(intersect,list(row.names(response_matrix),
row.names(feature_matrix_all_neighbour_pkgs),
row.names(feature_matrix_titles_descriptions_packages_cosine_df),
row.names(feature_matrix_author_task_views)))
final_package_names = unique(final_package_names)
response_matrix                                       = response_matrix[final_package_names,]
feature_matrix_all_neighbour_pkgs                     = feature_matrix_all_neighbour_pkgs[final_package_names,]
feature_matrix_titles_descriptions_packages_cosine_df = feature_matrix_titles_descriptions_packages_cosine_df[final_package_names,]
feature_matrix_author_task_views                      = feature_matrix_author_task_views[final_package_names,]
# Double checking duplicates
response_matrix                                       = response_matrix[!duplicated(row.names(response_matrix)),]
feature_matrix_all_neighbour_pkgs                     = feature_matrix_all_neighbour_pkgs[!duplicated(row.names(feature_matrix_all_neighbour_pkgs)),]
feature_matrix_titles_descriptions_packages_cosine_df = feature_matrix_titles_descriptions_packages_cosine_df[!duplicated(row.names(feature_matrix_titles_descriptions_packages_cosine_df)),]
feature_matrix_author_task_views                      = feature_matrix_author_task_views[!duplicated(row.names(feature_matrix_author_task_views)),]
features = merge(feature_matrix_titles_descriptions_packages_cosine_df, feature_matrix_all_neighbour_pkgs_df, by="row.names", all.x = TRUE, )
rownames(features) = features[,"Row.names"]
features = features[,colnames(features) != "Row.names"]
colnames(features) = gsub(colnames(features), pattern = "\\.x", replacement = ".text")
colnames(features) = gsub(colnames(features), pattern = "\\.y", replacement = ".neigh_packs")
features = merge(features, feature_matrix_author_task_views_df, by="row.names", all.x = TRUE)
# features = as.numeric(as.matrix(features))
nrow(features)
rownames(features) = features[,"Row.names"]
features = features[,colnames(features) != "Row.names"]
return(list("response_matrix" = response_matrix, "features" = features, "All_data" = All_data, "pac_network_igraph" = pac_network_igraph, "input_CRAN_data" = input_CRAN_data))
}
load_all()
devtools::load_all()
debugSource("~/Documents/Projects/CTVsuggest/R/get_create_features.R")
get_create_features
get_create_features(TEST = T, limiting_n_observations = 100)
RWsearch::tvdb_pkgs(char = RWsearch::tvdb_vec(input_CRAN_data$tvdb))
RWsearch::tvdb_vec(input_CRAN_data$tvdb)
RWsearch::tvdb_pkgs()
RWsearch::tvdb_pkgs(tvdb = input_CRAN_data$tvdb)
RWsearch::tvdb_pkgs(char = NULL, tvdb = input_CRAN_data$tvdb)
RWsearch::tvdb_pkgs(tvdb = RWsearch::tvdb_vec(input_CRAN_data$tvdb))
RWsearch::tvdb_vec(input_CRAN_data$tvdb)
RWsearch::tvdb_pkgs(char = RWsearch::tvdb_vec(input_CRAN_data$tvdb))
RWsearch::tvdb_pkgs
input_CRAN_data$tvdb
RWsearch::tvdb_pkgs
is.list(input_CRAN_data$tvdb)
RWsearch::tvdb_vec()
RWsearch::tvdb_vec(input_CRAN_data$tvdb)
RWsearch::tvdb_pkgs(tvdb = (input_CRAN_data$tvdb))
RWsearch::tvdb_pkgs(tvdb = input_CRAN_data$tvdb)
RWsearch::tvdb_pkgs(tvdb = RWsearch::tvdb_vec(input_CRAN_data$tvdb))
RWsearch::tvdb_pkgs(char = RWsearch::tvdb_vec(input_CRAN_data$tvdb), tvdb = input_CRAN_data$tvdb)
RWsearch::tvdb_pkgs(char = RWsearch::tvdb_vec(input_CRAN_data$tvdb))
debugSource("~/Documents/Projects/CTVsuggest/R/get_create_features.R")
get_create_features(TEST = T)
RWsearch::tvdb_pkgs(char = RWsearch::tvdb_vec(input_CRAN_data$tvdb))
debugSource("~/Documents/Projects/CTVsuggest/R/get_create_features.R")
get_create_features(TEST = T)
RWsearch::tvdb_pkgs(char = RWsearch::tvdb_vec(input_CRAN_data$tvdb), tvdb = input_CRAN_data$tvdb)
debugSource("~/Documents/Projects/CTVsuggest/R/get_create_features.R")
devtools::load_all()
debugSource("~/Documents/Projects/CTVsuggest/R/get_create_features.R")
get_create_features(TEST = T)
RWsearch::tvdb_vec(tvdb)
devtools::load_all()
CTVsuggest:::get_create_features()
features_test = CTVsuggest:::get_create_features(TEST = T)
devtools::load_all()
features_test = CTVsuggest:::get_create_features(TEST = T)
devtools::document()
usethis::use_r("get_CRAN_logs")
TEST = T
limiting_n_observations = 100
get_create_features_output = CTVsuggest:::get_create_features(TEST = TEST, limiting_n_observations = limiting_n_observations)
get_create_features_output$input_CRAN_data
input_CRAN_data = get_create_features_output$input_CRAN_data
tvdb = input_CRAN_data$tvdb
task_views = tvdb_vec()
task_views = RWsearch::tvdb_vec()
date = lubridate::today()
date
mnth_dwnloads = vector(length = length(task_views), mode = "list")
names(mnth_dwnloads) = tvdb_vec()
names(mnth_dwnloads) = RWsearch::tvdb_vec()
install.packages("cranlogs")
i = "Cluster"
# i = "Cluster"
# pkg = tvdb_vec()[i]
total_dec_21 <- cranlogs::cran_downloads(from = date %m-% months(1), to = date, packages = RWsearch::tvdb_pkgs(char = i, tvdb = input_CRAN_data$tvdb))
date lubridate::`.__T__%m-%:lubridate` months(1)
date lubridate::`.__T__%m-%:lubridate` lubridate::months(1)
date %m-%:lubridate` lubridate::months(1)
usethis::use_package("tools")
usethis::use_package("cranly")
usethis::use_package("stringr")
usethis::use_package("dplyr")
usethis::use_package("tidytext")
usethis::use_package("textstem")
usethis::use_package("pbapply")
usethis::use_package("lsa")
usethis::use_package("lsa")
usethis::use_package("pbapply")
devtools::document()
devtools::document()
devtools::load_all()
get_create_features_output = CTVsuggest:::get_create_features(TEST = TEST, limiting_n_observations = limiting_n_observations)
TEST = T
limiting_n_observations = 100
get_create_features_output = CTVsuggest:::get_create_features(TEST = TEST, limiting_n_observations = limiting_n_observations)
input_CRAN_data = get_create_features_output$input_CRAN_data
tvdb = input_CRAN_data$tvdb
task_views = RWsearch::tvdb_vec()
date = lubridate::today()
mnth_dwnloads = vector(length = length(task_views), mode = "list")
names(mnth_dwnloads) = RWsearch::tvdb_vec()
# creates list with number of monthly downloads for each package within Task View
for(i in RWsearch::tvdb_vec()){
# i = "Cluster"
# pkg = tvdb_vec()[i]
total_dec_21 <- cranlogs::cran_downloads(from = date %m-% months(1), to = date, packages = RWsearch::tvdb_pkgs(char = i, tvdb = input_CRAN_data$tvdb))
total_dec_21$package = factor(total_dec_21$package)
mnth_dwnloads[[i]] = total_dec_21 %>%
group_by(package) %>%
summarise(sum = sum(count))
}
devtools::document()
devtools::load_all()
# creates list with number of monthly downloads for each package within Task View
for(i in RWsearch::tvdb_vec()){
# i = "Cluster"
# pkg = tvdb_vec()[i]
total_dec_21 <- cranlogs::cran_downloads(from = date %m-% months(1), to = date, packages = RWsearch::tvdb_pkgs(char = i, tvdb = input_CRAN_data$tvdb))
total_dec_21$package = factor(total_dec_21$package)
mnth_dwnloads[[i]] = total_dec_21 %>%
group_by(package) %>%
summarise(sum = sum(count))
}
# creates list with number of monthly downloads for each package within Task View
for(i in RWsearch::tvdb_vec()){
# i = "Cluster"
# pkg = tvdb_vec()[i]
total_dec_21 <- cranlogs::cran_downloads(from = date %m-% months(1), to = date, packages = RWsearch::tvdb_pkgs(char = i, tvdb = input_CRAN_data$tvdb))
total_dec_21$package = factor(total_dec_21$package)
mnth_dwnloads[[i]] = total_dec_21 %>%
dplyr::group_by(package) %>%
dplyr::summarise(sum = sum(count))
}
#### Finding packages that have no assigned Task View that meet the decided download threshold ####
# Vector of package names that do not have a Task View
no_tsk_view_packages = igraph::V(pac_network_igraph)$name[!(igraph::V(pac_network_igraph)$name %in% Reduce(c,RWsearch::tvdb_pkgs(char = RWsearch::tvdb_vec(input_CRAN_data$tvdb), tvdb = input_CRAN_data$tvdb)))]
#### Finding packages that have no assigned Task View that meet the decided download threshold ####
# Vector of package names that do not have a Task View
no_tsk_view_packages = igraph::V(get_create_features_output$pac_network_igraph)$name[!(igraph::V(get_create_features_output$pac_network_igraph)$name %in% Reduce(c,RWsearch::tvdb_pkgs(char = RWsearch::tvdb_vec(input_CRAN_data$tvdb), tvdb = input_CRAN_data$tvdb)))]
# Remove R package, as it cannot be queried with other packages with cran_downloads
no_tsk_view_packages = no_tsk_view_packages[-which(no_tsk_view_packages == "R")]
# splitting into chunks
chunk_size = 500
n_chunks = ceiling(length(no_tsk_view_packages)/chunk_size)
no_tsk_downloads_ls = vector(mode = "list", length = n_chunks)
# splitting into chunks
chunk_size = 500
n_chunks = ceiling(length(no_tsk_view_packages)/chunk_size)
no_tsk_downloads_ls = vector(mode = "list", length = n_chunks)
i = 1
print(i)
j = (1 + (chunk_size*(i - 1))):(chunk_size + (chunk_size*(i - 1)))
no_tsk_downloads <- cranlogs::cran_downloads(from = date %m-% months(1), to = date, packages = no_tsk_view_packages[j])
no_tsk_downloads_ls[[i]] = no_tsk_downloads %>%
dplyr::group_by(package) %>%
dplyr::summarise(sum = sum(count)) %>%
filter(sum > 2500)
no_tsk_downloads_ls[[i]] = no_tsk_downloads %>%
dplyr::group_by(package) %>%
dplyr::summarise(sum = sum(count)) %>%
dplyr::filter(sum > 2500)
devtools::document()
devtools::load_all()
CTVsuggest:::.__NAMESPACE__.
CTVsuggest:::get_CRAN_logs(TEST = T)
debugSource("~/Documents/Projects/CTVsuggest/R/get_CRAN_logs.R")
get_CRAN_logs(TEST = TRUE)
debugSource("~/Documents/Projects/CTVsuggest/R/get_CRAN_logs.R")
get_CRAN_logs(TEST = TRUE)
debugSource("~/Documents/Projects/CTVsuggest/R/get_CRAN_logs.R")
get_CRAN_logs(TEST = TRUE)
debugSource("~/Documents/Projects/CTVsuggest/R/get_CRAN_logs.R")
get_CRAN_logs(TEST = TRUE)
get_CRAN_logs(TEST = TRUE)
cranlogs::cran_downloads(from = date %m-% months(1), to = date, packages = RWsearch::tvdb_pkgs(char = i, tvdb = input_CRAN_data$tvdb))
i = 1
j = (1 + (chunk_size*(i - 1))):(chunk_size + (chunk_size*(i - 1)))
no_tsk_downloads <- cranlogs::cran_downloads(from = date %m-% months(1), to = date, packages = no_tsk_view_packages[j])
no_tsk_downloads_ls[[i]] = no_tsk_downloads %>%
dplyr::group_by(package) %>%
dplyr::summarise(sum = sum(count)) %>%
dplyr::filter(sum > 2500)
# final chunk
j = (((n_chunks -1) * chunk_size) + 1):length(no_tsk_view_packages)
cranlogs::cran_downloads(from = date %m-% months(1), to = date, packages = no_tsk_view_packages[j])
no_tsk_downloads_ls[[n_chunks]] = no_tsk_downloads %>%
dplyr::group_by(package) %>%
dplyr::summarise(sum = sum(count)) %>%
dplyr::filter(sum > 2500)
# Number of not assigned packages that meet threshold
length(unique(rbindlist(no_tsk_downloads_ls)$package))
devtools::document()
devtools::check()
devtools::document()
