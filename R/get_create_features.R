#' Creates a feature matrix for CRAN packages
#'
#' @description
#' `get_create_features()` returns a set of features, and a response matrix for all packages whose data has been extracted.
#' A subset of these are then used for model training and testing. And the features of the packages are required to generate model predictions, using the trained model.
#'
#' @details
#' The `get_create_features()` function is run inside [get_CRAN_logs()].
#'
#' `get_create_features()` carries out the following steps:
#'  * Firstly, CRAN packages with no author have their maintainer set as the author in the `CRAN_cranly_data` object.
#'  * Then using the [cranly::build_network()], Author and Package \pkg{cranly} networks are built.
#'  * Next a list is created, with an element for each CRAN package that is assigned to at least one Task View.
#'    Each element is a character vector with the name of Task Views that the corresponding package is assigned to.
#'  * Response matrix is created - object is described in the \strong{Value} section of documentation.
#'  * The feature matrices are then created, these are matrices where each row corresponds to a feature vector for a CRAN package.
#'  The final feature matrix is then a combination of each of these individual matrices.
#'
#'  In the description of the feature matrices below, let \eqn{x} denote an example CRAN package.
#'  \describe{
#'     \item{Package Dependencies}{Feature vector of a package \eqn{x}, is the distribution of the Task View assignation of the hard dependencies of \eqn{x}.
#'     For example if a quarter of the hard dependencies of \eqn{x} belong to Bayesian than the corresponding element of the vector will be 0.25.}
#'     \item{Other Author Packages}{Feature vector of a package \eqn{x}, is the distribution of the Task View assignation of other packages developed by the authors of \eqn{x}.}
#'     \item{Text Data}{`feature_matrix_titles_descriptions_packages_cosine` object is created by the [get_NLP()] function.}
#'  }
#'
#'
#' @inheritParams get_NLP
#'
#' @return Returns
#'\itemize{
#'   \item `response_matrix` - Matrix with a row for each CRAN package, and a column for each CRAN Task View.
#'   A value of 1 denotes that the package is assigned to the Task View of the corresponding column, and a value of zero if not.
#'   \item `features` - Matrix with a row for each CRAN package, and a column for each variable.
#'   This feature matrix is constructed using each of the three different types of features as described
#'   at the end of the \strong{Details} section.
#'   \item `All_data` - List containing a package and an author network created with cranly.
#'   \item `pac_network_igraph` - igraph version of the cranly package network.
#'   \item `input_CRAN_data` - This just a list containing all of the data created by [get_NLP()], so that it is carried forward.
#' }
#'

get_create_features = function(TEST = FALSE,
                               limiting_n_observations = 100,
                               get_input_stored = FALSE,
                               get_input_path = "tests/testthat/fixtures/get_NLP_output/get_NLP_output.rds",
                               save_output = FALSE,
                               save_path = "tests/testthat/fixtures/get_create_features_output",
                               file_name = "get_create_features_output.rds") {


  # Objects needed to run generated by previous script:
  # tvdb
  # CRAN_data
  # CRAN_cranly_data
  # all_CRAN_pks
  # feature_matrix_titles_descriptions_packages_cosine


  # Objects Outputted:
  # response_matrix
  # features
  # All_data
  # pac_network_igraph
  # final_package_names


#### ----------------------------------------------------------------------------------------------- ####
  # Getting data
  # For testing may want to use prestored input object
  if (get_input_stored) {
    get_NLP_output = readRDS(get_input_path)
    input_CRAN_data = get_NLP_output$input_CRAN_data
    tvdb = input_CRAN_data$tvdb
    TEST = attributes(input_CRAN_data)$TEST
    limiting_n_observations = attributes(input_CRAN_data)$limiting_n_observations

  } else {

    # Get required objects from CTVsuggest:::get_NLP()
    get_NLP_output = CTVsuggestTrain:::get_NLP(TEST = TEST, limiting_n_observations = limiting_n_observations)
    input_CRAN_data = get_NLP_output$input_CRAN_data
    tvdb = input_CRAN_data$tvdb
  }


#### ----------------------------------------------------------------------------------------------- ####


#### ----------------------------------------------------------------------------------------------- ####

  ## Replacing missing authors with maintainers ##
  # For some packages on CRAN the authors have not been listed in the standard way.
  # Which causes these packages to have zero authors listed.
  # The work around I have used is by setting the maintainer as the author

  # Identifying packages with no authors
  index_of_no_authors = which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0)

  # replacing with maintainers
  if (length(which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0)) > 0) {
    for (i in 1:length(which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0))) {
    #i = 1
    input_CRAN_data$CRAN_cranly_data$author[[index_of_no_authors[i]]] = input_CRAN_data$CRAN_cranly_data$maintainer[index_of_no_authors[i]]
    }
  }

#### ----------------------------------------------------------------------------------------------- ####


#### ----------------------------------------------------------------------------------------------- ####

  ## Building author and package networks ##
  # Note that if running a test and have restricted the number of packages,
  # when building the package network the number of packages listed in the node set will increase.
  # Because we are looking at all dependencies of these packages.
  # Building the package network will also add packages that are not hosted on CRAN but are hosted on other repositories.
  aut_network <- cranly::build_network(input_CRAN_data$CRAN_cranly_data, perspective = 'author')
  pac_network <- cranly::build_network(input_CRAN_data$CRAN_cranly_data, perspective = 'package')
  All_data = list("aut_network" = aut_network, "pac_network" = pac_network)


  # All_data_igraph = as.igraph(All_data$pac_network)
  pac_network_igraph = igraph::as.igraph(All_data$pac_network)

#### ----------------------------------------------------------------------------------------------- ####


#### ----------------------------------------------------------------------------------------------- ####


  # I now want to create a vector of packages that are assigned to a Task View and are hosted on CRAN
  # As there exist packages that belong to a Task View but are not hosted on CRAN

  # Character vector containing names of current Task Views
  task_views = RWsearch::tvdb_vec(input_CRAN_data$tvdb)

  # Packages that are assigned to a Task View
  task_view_packages = Reduce(c,RWsearch::tvdb_pkgs(char = task_views, tvdb = input_CRAN_data$tvdb))
  task_view_packages = unique(task_view_packages)
  # Removing the packages that are not hosted on CRAN
  packages_assigned_Task_View = task_view_packages[task_view_packages %in% input_CRAN_data$all_CRAN_pks]
  # Removing duplicates
  packages_assigned_Task_View = unique(packages_assigned_Task_View)


  # Creating list of packages with the Task Views assigned to each one
  taskviews_of_pckgs = vector(mode = "list", length = length(packages_assigned_Task_View))

  for(j in seq_len(length(packages_assigned_Task_View))){
    for(i in seq_len(length(task_views))){

      if(packages_assigned_Task_View[j] %in% RWsearch::tvdb_pkgs(char = task_views[i], tvdb = input_CRAN_data$tvdb)) {

        taskviews_of_pckgs[[j]] = c(taskviews_of_pckgs[[j]], task_views[i])

      }
    }
  }


  names(taskviews_of_pckgs) = packages_assigned_Task_View

  #taskviews_of_pckgs$trackeR

#### ----------------------------------------------------------------------------------------------- ####


#### ----------------------------------------------------------------------------------------------- ####

  # Creating the response matrix
  response_matrix = matrix(0, nrow = length(input_CRAN_data$all_CRAN_pks), ncol = length(task_views) + 1)
  colnames(response_matrix) = c(task_views, "none")

  # Creating matrix that denotes which Task View(s) each package belongs to
  for (i in seq_len(length(input_CRAN_data$all_CRAN_pks))) {
    #i = 6214
    #i = 13672

    if (is.null(taskviews_of_pckgs[[input_CRAN_data$all_CRAN_pks[i]]])) {

      response_matrix[i,"none"] = 1

    } else {


      response_matrix[i,taskviews_of_pckgs[[input_CRAN_data$all_CRAN_pks[i]]]] = 1

    }
  }

  rownames(response_matrix) = input_CRAN_data$all_CRAN_pks

  #response_matrix["trackeR",]

#### ----------------------------------------------------------------------------------------------- ####

#### ----------------------------------------------------------------------------------------------- ####

  ### Creating features/predictors ###

  ## Creating Proportion of neighboring packages feature matrix ##
  message("Creating Proportion of neighboring packages feature matrix")


  # Giving a Task View attribute to the pac_network
  pac_network_igraph = igraph::set_vertex_attr(pac_network_igraph, name = "taskview",
                                       index = packages_assigned_Task_View,
                                       taskviews_of_pckgs[packages_assigned_Task_View])

  # check:
  # V(pac_network_igraph)$taskview[V(pac_network_igraph)$name == "ggplot2"]
  # V(pac_network_igraph)$taskview[V(pac_network_igraph)$name == "trackeR"]


  # Deleting the soft dependencies between packages
  soft_dependencies_edges = which(!is.element(igraph::E(pac_network_igraph)$type, c("depends","imports", "linking_to")))
  taskviews_pac_network_rem_edges_igraph = igraph::delete.edges(pac_network_igraph, soft_dependencies_edges)



  # Creating matrix where for each package it gives the proportion of immediate hard dependencies.
  # In the `neighbours` function `mode` is set to `c("all")` meaning that we are looking at
  # dependencies of a package and its reverse dependencies.
  feature_matrix_all_neighbour_pkgs = matrix(0, nrow = length(input_CRAN_data$all_CRAN_pks), ncol = length(task_views) + 1)
  colnames(feature_matrix_all_neighbour_pkgs) = c(task_views, "none")

  for(i in 1:length(input_CRAN_data$all_CRAN_pks)){

    #print(i)
    neigh = igraph::neighbors(taskviews_pac_network_rem_edges_igraph, input_CRAN_data$all_CRAN_pks[i], mode = c("all"))$taskview
    n_none = sum(unlist(lapply(neigh, function(x){is.null(x)})))
    props = (prop.table(table(c(unlist(neigh), rep("none", n_none)))))

    feature_matrix_all_neighbour_pkgs[i,names(props)] = as.vector(props)

  }

  rownames(feature_matrix_all_neighbour_pkgs) = input_CRAN_data$all_CRAN_pks


#### ----------------------------------------------------------------------------------------------- ####


#### ----------------------------------------------------------------------------------------------- ####

  ### Proportion of other packages that Author worked on ###
  message("Creating Proportion of other packages that Author worked on feature matrix")
  # feature_matrix_author_task_views = board %>% pin_read("feature_matrix_author_task_views")

  # calculated by taking the authors of the package, getting the packages that they worked on.
  # Then looking at the proportion of the assignment to Task Views of these packages

  authors_of_packages = All_data$pac_network$nodes$author
  names(authors_of_packages) = All_data$pac_network$nodes$package
  authors_of_packages = authors_of_packages[input_CRAN_data$all_CRAN_pks]


  packages_of_authors = All_data$aut_network$nodes$package
  names(packages_of_authors) = All_data$aut_network$nodes$author


  fun1 = function(x){

    # when given a vector of Authors, returns a vector of the proportion of the Task Views of the packages qorked on by the authors
    z = unlist(taskviews_of_pckgs[unique(unlist(packages_of_authors[x]))])

    if(is.null(z)){
      author_tsk_view_prop = c(rep(0,length(RWsearch::tvdb_vec(tvdb))),1)
      names(author_tsk_view_prop) = c(RWsearch::tvdb_vec(tvdb), "none")


    }else{
      author_tsk_view_prop = prop.table(table(z))
      mat_fill = matrix(0, nrow = 1, ncol = length(RWsearch::tvdb_vec(tvdb)) + 1)
      colnames(mat_fill) = c(RWsearch::tvdb_vec(tvdb), "none")
      mat_fill[1,names(author_tsk_view_prop)] = as.vector(author_tsk_view_prop)
      author_tsk_view_prop = mat_fill
    }

    return(author_tsk_view_prop)

  }

  feature_matrix_author_task_views = pbapply::pblapply(authors_of_packages, fun1)

  feature_matrix_author_task_views = do.call(rbind, feature_matrix_author_task_views)
  row.names(feature_matrix_author_task_views) = names(authors_of_packages)

  colnames(feature_matrix_author_task_views) = paste0(colnames(feature_matrix_author_task_views), ".Author_props")

#### ----------------------------------------------------------------------------------------------- ####


#### ----------------------------------------------------------------------------------------------- ####

  ### merging feature matrices ###

  # The labeled data consists of:
  #             > Packages with assigned Task Views
  #             > Packages with no Task View that meet assigned download Threshold

  # converting individual feature objects to data frames
  feature_matrix_all_neighbour_pkgs_df = as.data.frame(feature_matrix_all_neighbour_pkgs)
  feature_matrix_author_task_views_df = as.data.frame(feature_matrix_author_task_views)
  feature_matrix_titles_descriptions_packages_cosine_df = as.data.frame(get_NLP_output$feature_matrix_titles_descriptions_packages_cosine)

  # transposing the NLP feature object
  feature_matrix_titles_descriptions_packages_cosine_df = t(feature_matrix_titles_descriptions_packages_cosine_df)


  # Removing duplicated rows
  response_matrix                                         = response_matrix[!duplicated(row.names(response_matrix)),]
  feature_matrix_all_neighbour_pkgs_df                    = feature_matrix_all_neighbour_pkgs_df[!duplicated(row.names(feature_matrix_all_neighbour_pkgs_df)),]
  feature_matrix_titles_descriptions_packages_cosine_df   = feature_matrix_titles_descriptions_packages_cosine_df[!duplicated(row.names(feature_matrix_titles_descriptions_packages_cosine_df)),]
  feature_matrix_author_task_views_df                     = feature_matrix_author_task_views_df[!duplicated(row.names(feature_matrix_author_task_views_df)),]


  # Making sure all feature matrices and response matrix have correct rownames in correct order
  ## Response matrix
  # response_matrix
  ## Package Dependencies
  # feature_matrix_all_neighbour_pkgs
  ## Text data
  # feature_matrix_titles_descriptions_packages_cosine_df
  ## Author collaborators
  # feature_matrix_author_task_views

  # Create a final vector of package names that have rows for all the feature matrices and response matrix
  # So what I have done is used rows that have data for all of the feature matrices and the response matrix
  final_package_names =
    Reduce(intersect,list(row.names(response_matrix),
                          row.names(feature_matrix_all_neighbour_pkgs_df),
                          row.names(feature_matrix_titles_descriptions_packages_cosine_df),
                          row.names(feature_matrix_author_task_views_df)))

  final_package_names = unique(final_package_names)

  response_matrix                                       = response_matrix[final_package_names,]
  feature_matrix_all_neighbour_pkgs_df                  = feature_matrix_all_neighbour_pkgs_df[final_package_names,]
  feature_matrix_titles_descriptions_packages_cosine_df = feature_matrix_titles_descriptions_packages_cosine_df[final_package_names,]
  feature_matrix_author_task_views_df                   = feature_matrix_author_task_views_df[final_package_names,]


  # Double checking duplicates
  response_matrix                                       = response_matrix[!duplicated(row.names(response_matrix)),]
  feature_matrix_all_neighbour_pkgs_df                  = feature_matrix_all_neighbour_pkgs[!duplicated(row.names(feature_matrix_all_neighbour_pkgs_df)),]
  feature_matrix_titles_descriptions_packages_cosine_df = feature_matrix_titles_descriptions_packages_cosine_df[!duplicated(row.names(feature_matrix_titles_descriptions_packages_cosine_df)),]
  feature_matrix_author_task_views_df                   = feature_matrix_author_task_views_df[!duplicated(row.names(feature_matrix_author_task_views_df)),]


  features = merge(feature_matrix_titles_descriptions_packages_cosine_df, feature_matrix_all_neighbour_pkgs_df, by="row.names", all.x = TRUE, )
  rownames(features) = features[,"Row.names"]
  features = features[,colnames(features) != "Row.names"]
  colnames(features) = gsub(colnames(features), pattern = "\\.x", replacement = ".text")
  colnames(features) = gsub(colnames(features), pattern = "\\.y", replacement = ".neigh_packs")


  features = merge(features, feature_matrix_author_task_views_df, by="row.names", all.x = TRUE)
  # features = as.numeric(as.matrix(features))
  nrow(features)
  rownames(features) = features[,"Row.names"]
  features = features[,colnames(features) != "Row.names"]




#### ----------------------------------------------------------------------------------------------- ####

  # Creating object to be returned. Which is a list made up of objects needed upstream
  list_to_return = list("response_matrix" = response_matrix, "features" = features, "All_data" = All_data,
                        "pac_network_igraph" = pac_network_igraph, "final_package_names" = final_package_names,
                        "input_CRAN_data" = input_CRAN_data)


  CTVsuggestTrain:::save_or_return_objects(TEST = TEST, list_to_return = list_to_return, limiting_n_observations = limiting_n_observations,
                                           save_output = save_output, save_path = save_path, file_name = file_name)


}


