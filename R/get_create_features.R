#' Title
#'
#' @param TEST Takes either TRUE or FALSE, if FALSE it use all available CRAN data otherwise it is restricted to a subset.
#' @param limiting_n_observations Integer that decides the size of the subset of `CRAN_data`, when `TEST` is [`TRUE`].
#'
#' @return
#'
#'
#' @examples
get_create_features = function(TEST = FALSE, limiting_n_observations = 100){


  get_NLP_output = CTVsuggest:::get_NLP(TEST = TEST, limiting_n_observations = limiting_n_observations)
  input_CRAN_data = get_NLP_output$input_CRAN_data
  tvdb = input_CRAN_data$tvdb




#### Objects needed to run generated by previous script ####
# tvdb
# CRAN_data
# CRAN_cranly_data
# all_CRAN_pks
# feature_matrix_titles_descriptions_packages_cosine


##### Objects Outputted ####
# response_matrix
# features
# All_data
# pac_network_igraph




#### ----------------------------------------------------------------------------------------------- ####

#### Replacing missing authors with maintainers ####
# For some packages on CRAN the authors have not been listed in the standard way.
# Which causes these packages to have zero authors listed.
# The work around I have used is by setting the maintainer as the author

# Identifying packages with no authors
index_of_no_authors = which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0)

# replacing with maintainers
  if(length(which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0)) > 0){
for(i in 1:length(which(unlist(lapply(input_CRAN_data$CRAN_cranly_data$author, length)) == 0))){
  #i = 1
  input_CRAN_data$CRAN_cranly_data$author[[index_of_no_authors[i]]] = input_CRAN_data$CRAN_cranly_data$maintainer[index_of_no_authors[i]]
}
  }

#### ----------------------------------------------------------------------------------------------- ####




#### ----------------------------------------------------------------------------------------------- ####

##### Building author and package networks ####
# Note that if running a test and have restricted the number of packages,
  # when building the package network the number of packages listed in the node set will increase.
  # Because we are looking at all dependencies of these packages.
  # Building the package network will also add packages that are not hosted on CRAN but are hosted on other repos.
aut_network <- cranly::build_network(input_CRAN_data$CRAN_cranly_data, perspective = 'author')
pac_network <- cranly::build_network(input_CRAN_data$CRAN_cranly_data, perspective = 'package')
All_data = list("aut_network" = aut_network, "pac_network" = pac_network)


# All_data_igraph = as.igraph(All_data$pac_network)
pac_network_igraph = igraph::as.igraph(All_data$pac_network)

#### ----------------------------------------------------------------------------------------------- ####



#### ----------------------------------------------------------------------------------------------- ####


# I now want to create a vector of packages that are assigned to a Task View and are hosted on CRAN
  # As there exist packages that belong to a Task View but are not hosted on CRAN

# Packages that are assigned to a Task View and are not hosted on CRAN
not_in_CRAN = Reduce(c,RWsearch::tvdb_pkgs(char = RWsearch::tvdb_vec(input_CRAN_data$tvdb), tvdb = input_CRAN_data$tvdb))[!(Reduce(c,RWsearch::tvdb_pkgs(char = RWsearch::tvdb_vec(input_CRAN_data$tvdb), tvdb = input_CRAN_data$tvdb)) %in% input_CRAN_data$CRAN_data$Package)]
packages_assigned_Task_View = Reduce(c,RWsearch::tvdb_pkgs(char = RWsearch::tvdb_vec(input_CRAN_data$tvdb), tvdb = input_CRAN_data$tvdb))
# Removing the packages that are not hosted on CRAN
packages_assigned_Task_View = packages_assigned_Task_View[!(packages_assigned_Task_View %in% not_in_CRAN)]
# Removing duplicates
packages_assigned_Task_View = unique(packages_assigned_Task_View)


# Just looking at Hard Depenedencies
# dep_imp_edges = which(!is.element(E(All_taskviews_igraph)$type, c("depends","imports", "linking_to")))
# All_taskviews_rem_edges_igraph = delete.edges(All_taskviews_igraph, dep_imp_edges)



##########################################################################################


#### Creating list of packages with the task views assigned to each one ####

# taskviews_of_pckgs     = board %>% pin_read("taskviews_of_pckgs")
# This code is a modified version of the generating_taskviews script

taskviews_of_pckgs = vector(mode = "list", length = length(packages_assigned_Task_View))

for(j in 1:length(packages_assigned_Task_View)){
  for(i in 1:length(tvdb)){
    print(paste(j,i))
    if(packages_assigned_Task_View[j] %in% RWsearch::tvdb_pkgs(char = RWsearch::tvdb_vec(input_CRAN_data$tvdb)[i], tvdb = input_CRAN_data$tvdb)) {

      taskviews_of_pckgs[[j]] = append(taskviews_of_pckgs[[j]], RWsearch::tvdb_vec(input_CRAN_data$tvdb)[i])

    }
  }
}


names(taskviews_of_pckgs) = packages_assigned_Task_View

#taskviews_of_pckgs$trackeR
# board %>% pin_write(taskviews_of_pckgs, "taskviews_of_pckgs", type = "rds")




##########################################################################################



########## Creating the response matrix #######

response_matrix = matrix(0, nrow = length(input_CRAN_data$all_CRAN_pks), ncol = length(RWsearch::tvdb_vec(tvdb)) + 1)
colnames(response_matrix) = c(RWsearch::tvdb_vec(tvdb), "none")

# Creating matrix that denotes which Task View(s) each package belongs to
for(i in 1:length(input_CRAN_data$all_CRAN_pks)){
  #i = 6214
  #i = 13672

  if(is.null(taskviews_of_pckgs[[input_CRAN_data$all_CRAN_pks[i]]])){

    response_matrix[i,"none"] = 1

  } else {


    response_matrix[i,taskviews_of_pckgs[[input_CRAN_data$all_CRAN_pks[i]]]] = 1

  }
}

rownames(response_matrix) = input_CRAN_data$all_CRAN_pks

#response_matrix["trackeR",]



##########################################################################################



########## Creating features/predictors ######

##### Creating  Proportion of neighboring packages feature matrix ####
message("Creating  Proportion of neighboring packages feature matrix")
# creating graph object removing soft dependencies

# Giving a Task View attribute to the pac_network
pac_network_igraph = igraph::set_vertex_attr(pac_network_igraph, name = "taskview",
                                     index = packages_assigned_Task_View,
                                     taskviews_of_pckgs[packages_assigned_Task_View])

# check:
# V(pac_network_igraph)$taskview[V(pac_network_igraph)$name == "ggplot2"]
# V(pac_network_igraph)$taskview[V(pac_network_igraph)$name == "trackeR"]


# Deleting the soft dependencies between packages
soft_dependencies_edges = which(!is.element(igraph::E(pac_network_igraph)$type, c("depends","imports", "linking_to")))
taskviews_pac_network_rem_edges_igraph = igraph::delete.edges(pac_network_igraph, soft_dependencies_edges)




# feature_matrix_all_neighbour_pkgs     = board %>% pin_read("feature_matrix_all_neighbour_pkgs")
# Creating matrix where for each package it gives the proportion of immediate hard dependencies.
# In the `neighbours` function `mode` is set to `c("all")` meaning that we are looking at on both
# dependencies of a package and its reverse dependencies.
feature_matrix_all_neighbour_pkgs = matrix(0, nrow = length(input_CRAN_data$all_CRAN_pks), ncol = length(RWsearch::tvdb_vec(tvdb)) + 1)
colnames(feature_matrix_all_neighbour_pkgs) = c(RWsearch::tvdb_vec(tvdb), "none")

for(i in 1:length(input_CRAN_data$all_CRAN_pks)){

  print(i)
  neigh = igraph::neighbors(taskviews_pac_network_rem_edges_igraph, input_CRAN_data$all_CRAN_pks[i], mode = c("all"))$taskview
  n_none = sum(unlist(lapply(neigh, function(x){is.null(x)})))
  props = (prop.table(table(c(unlist(neigh), rep("none", n_none)))))

  feature_matrix_all_neighbour_pkgs[i,names(props)] = as.vector(props)

}

rownames(feature_matrix_all_neighbour_pkgs) = input_CRAN_data$all_CRAN_pks






##### Load Features using text data of packages #####
# This has been created in the NLP R script. Reliant on the number of package available on GitHub page.








##### Proportion of other packages that Author worked on  ####
message("Creating Proportion of other packages that Author worked on feature matrix")
# feature_matrix_author_task_views = board %>% pin_read("feature_matrix_author_task_views")

# calculated by taking the authors of the package, getting the packages that they worked on.
# Then looking at the proportion of the assignment to Task Views of these packages

authors_of_packages = All_data$pac_network$nodes$author
names(authors_of_packages) = All_data$pac_network$nodes$package
authors_of_packages = authors_of_packages[input_CRAN_data$all_CRAN_pks]


packages_of_authors = All_data$aut_network$nodes$package
names(packages_of_authors) = All_data$aut_network$nodes$author


fun1 = function(x){

  # when given a vector of Authors, returns a vector of the proportion of the Task Views of the packages qorked on by the authors
  z = unlist(taskviews_of_pckgs[unique(unlist(packages_of_authors[x]))])

  if(is.null(z)){
    author_tsk_view_prop = c(rep(0,length(RWsearch::tvdb_vec(tvdb))),1)
    names(author_tsk_view_prop) = c(RWsearch::tvdb_vec(tvdb), "none")


  }else{
    author_tsk_view_prop = prop.table(table(z))
    mat_fill = matrix(0, nrow = 1, ncol = length(RWsearch::tvdb_vec(tvdb)) + 1)
    colnames(mat_fill) = c(RWsearch::tvdb_vec(tvdb), "none")
    mat_fill[1,names(author_tsk_view_prop)] = as.vector(author_tsk_view_prop)
    author_tsk_view_prop = mat_fill
  }

  return(author_tsk_view_prop)

}

feature_matrix_author_task_views = pbapply::pblapply(authors_of_packages, fun1)

feature_matrix_author_task_views = do.call(rbind, feature_matrix_author_task_views)
row.names(feature_matrix_author_task_views) = names(authors_of_packages)

colnames(feature_matrix_author_task_views) = paste0(colnames(feature_matrix_author_task_views), ".Author_props")

##########################################################################################











########## Creating training and testing data sets ##########################################################################################
# I am going to split the labeled data with 80:20 ratio
# The labeled data consists of:
#             > Packages with assigned Task Views
#             > Packages with no Task View that meet assigned download Threshold




# merging feature matrices
feature_matrix_all_neighbour_pkgs_df = as.data.frame(feature_matrix_all_neighbour_pkgs)
feature_matrix_author_task_views_df = as.data.frame(feature_matrix_author_task_views)

feature_matrix_titles_descriptions_packages_cosine_df = as.data.frame(get_NLP_output$feature_matrix_titles_descriptions_packages_cosine)
feature_matrix_titles_descriptions_packages_cosine_df = t(feature_matrix_titles_descriptions_packages_cosine_df)


# Making sure all feature matrices and response matrix have correct rownames in correct order
# Response matrix
response_matrix
# Package Dependencies
feature_matrix_all_neighbour_pkgs
# Text data
feature_matrix_titles_descriptions_packages_cosine_df
feature_matrix_titles_descriptions_packages_cosine_df = feature_matrix_titles_descriptions_packages_cosine_df[input_CRAN_data$all_CRAN_pks,]
feature_matrix_titles_descriptions_packages_cosine_df
# Author collaborators
feature_matrix_author_task_views

# Create a final vector of package names that have rows for all the feature matrices and response matrix
# So what I have done is used rows that have data for all of the feature matrices and the response matrix
final_package_names =
  Reduce(intersect,list(row.names(response_matrix),
                        row.names(feature_matrix_all_neighbour_pkgs),
                        row.names(feature_matrix_titles_descriptions_packages_cosine_df),
                        row.names(feature_matrix_author_task_views)))

final_package_names = unique(final_package_names)

response_matrix                                       = response_matrix[final_package_names,]
feature_matrix_all_neighbour_pkgs                     = feature_matrix_all_neighbour_pkgs[final_package_names,]
feature_matrix_titles_descriptions_packages_cosine_df = feature_matrix_titles_descriptions_packages_cosine_df[final_package_names,]
feature_matrix_author_task_views                      = feature_matrix_author_task_views[final_package_names,]


# Double checking duplicates
response_matrix                                       = response_matrix[!duplicated(row.names(response_matrix)),]
feature_matrix_all_neighbour_pkgs                     = feature_matrix_all_neighbour_pkgs[!duplicated(row.names(feature_matrix_all_neighbour_pkgs)),]
feature_matrix_titles_descriptions_packages_cosine_df = feature_matrix_titles_descriptions_packages_cosine_df[!duplicated(row.names(feature_matrix_titles_descriptions_packages_cosine_df)),]
feature_matrix_author_task_views                      = feature_matrix_author_task_views[!duplicated(row.names(feature_matrix_author_task_views)),]

features = merge(feature_matrix_titles_descriptions_packages_cosine_df, feature_matrix_all_neighbour_pkgs_df, by="row.names", all.x = TRUE, )
rownames(features) = features[,"Row.names"]
features = features[,colnames(features) != "Row.names"]
colnames(features) = gsub(colnames(features), pattern = "\\.x", replacement = ".text")
colnames(features) = gsub(colnames(features), pattern = "\\.y", replacement = ".neigh_packs")


features = merge(features, feature_matrix_author_task_views_df, by="row.names", all.x = TRUE)
# features = as.numeric(as.matrix(features))
nrow(features)
rownames(features) = features[,"Row.names"]
features = features[,colnames(features) != "Row.names"]




return(list("response_matrix" = response_matrix, "features" = features, "All_data" = All_data, "pac_network_igraph" = pac_network_igraph, "input_CRAN_data" = input_CRAN_data))

}


